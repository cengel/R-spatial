[["index.html", "Using Spatial Data with R Prerequisites and Preparations References Acknowledgements", " Using Spatial Data with R Claudia A Engel Last updated: February 19, 2024 Prerequisites and Preparations To get the most out of this workshop you should have: a basic knowledge of R and/or be familiar with the topics covered in the Introduction to R. have a recent version of R and RStudio installed. Recommended: Create a new RStudio project R-spatial in a new folder R-spatial. Create a new folder under R-spatial and call it data. Open up a new R Script file and call it R-spatial.R for the code you’ll create during the workshop. If you have your working directory set to R-spatial which contains a folder called data you can copy, paste, and run the following lines in R: download.file(&quot;http://bit.ly/R-spatial-data&quot;, &quot;R-spatial-data.zip&quot;) unzip(&quot;R-spatial-data.zip&quot;, exdir = &quot;data&quot;) You can also download the data manually here R-spatial-data.zip and extract them in the data folder. Install and load the following libraries: sf terra tidyverse For the mapping section install and load these additional libraries: classInt RColorBrewer ggplot2 ggmap tmap leaflet(On Mac installing binary version is ok) References Lovelace, R., Nowosad, J., Muenchow. J. (2024): Geocomputation with R Pebesma, E. Bivand, R. (2023): Spatial Data Science Gimond, M (2023): Intro to GIS and Spatial Analysis Spatial Data Analysis and Modeling with R and terra CRAN Task View: Analysis of Spatial Data Acknowledgements Some of the materials for this tutorial are adapted from http://datacarpentry.org "],["intro.html", "Chapter 1 Introduction to spatial data in R 1.1 The sf package 1.2 Creating a spatial object from a lat/lon table 1.3 Loading shape files into R 1.4 Raster data in R", " Chapter 1 Introduction to spatial data in R Learning Objectives Read table with geo coordinates into sf object Read shapefiles into sf object Examine sf objects Use base plot with sf objects and attribute data Read GeoTiff single and multiband into a SpatRaster object Examine SpatRaster objects 1.1 The sf package The sf1 package was first released on CRAN in late October 2016, and has in the mean time superseded the original R Package for storing and manipulating spatial data, sp, which was first released in 2005. sp is still actively maintained, but less often used now, so you should be aware of it, but we will not teach it here. Figure 1.1: sf vs sp downloads on CRAN sf implements a formal standard called “Simple Features” that specifies a storage and access model of spatial geometries (point, line, polygon). A feature geometry is called simple when it consists of points connected by straight line pieces, and does not intersect itself. This standard has been adopted widely, not only by spatial databases such as PostGIS, but also more recent standards such as GeoJSON. If you work with PostGis or GeoJSON you may have come across the WKT (well-known text) format (Fig 1.1 and 1.2) Figure 1.2: Well-Known-Text Geometry primitives (wikipedia) Figure 1.3: Well-Known-Text Multipart geometries (wikipedia) sf implements this standard natively in R. In sf spatial objects are stored as a tabular format (data frame) with a special column that contains the information for the geometry coordinates. That special column holds a list with the same length as the number of rows in the data frame. Each of the individual list elements then can be of any length needed to hold the coordinates that correspond to an individual feature. sf objects are built up using the following structures: sfg - simple feature geometry (one feature) sfc - simple feature collection (a collection of sfg) sf - simple feature object (sfc with data attributes) So to create a spatial sf object manually the basic steps would be: I. Create geometric objects (topology) Geometric objects (simple features) can be created from a numeric vector, matrix or a list with the coordinates. They are called sfg objects for Simple Feature Geometry.b There are functions that help create simple feature geometries, like st_point(), st_linestring(), st_polygon() and more. II. Combine all individual single feature objects for the special column. The feature geometries are then combined into a Simple Feature Collection with st_sfc(). which is nothing other than a simple feature geometry list-column. The sfc object also holds the bounding box and the projection information. III. Add attributes. Lastly, we add the attributes to the the simple feature collection with the st_sf() function. This function extends the well known data frame in R with a column that holds the simple feature collection. To create a network of highways we would first generate LINESTRINGs as simple feature geometries out of a matrix with coordinates: lnstr_sfg1 &lt;- st_linestring(matrix(runif(6), ncol=2)) lnstr_sfg2 &lt;- st_linestring(matrix(runif(6), ncol=2)) class(lnstr_sfg1) #&gt; [1] &quot;XY&quot; &quot;LINESTRING&quot; &quot;sfg&quot; We would then combine this into a simple feature collection : (lnstr_sfc &lt;- st_sfc(lnstr_sfg1, lnstr_sfg2)) #&gt; Geometry set for 2 features #&gt; Geometry type: LINESTRING #&gt; Dimension: XY #&gt; Bounding box: xmin: 0.1766943 ymin: 0.08299711 xmax: 0.7724545 ymax: 0.7783025 #&gt; CRS: NA #&gt; LINESTRING (0.1766943 0.2560145, 0.614864 0.725... #&gt; LINESTRING (0.7724545 0.7783025, 0.5389782 0.08... And lastly create a data frame from above to generate the sf object: dfr &lt;- data.frame(id = c(&quot;hwy1&quot;, &quot;hwy2&quot;), cars_per_hour = c(78, 22)) (lnstr_sf &lt;- st_sf(dfr , lnstr_sfc)) #&gt; Simple feature collection with 2 features and 2 fields #&gt; Geometry type: LINESTRING #&gt; Dimension: XY #&gt; Bounding box: xmin: 0.1766943 ymin: 0.08299711 xmax: 0.7724545 ymax: 0.7783025 #&gt; CRS: NA #&gt; id cars_per_hour lnstr_sfc #&gt; 1 hwy1 78 LINESTRING (0.1766943 0.256... #&gt; 2 hwy2 22 LINESTRING (0.7724545 0.778... There are many methods available in the sf package, to find out use methods(class=&quot;sf&quot;) #&gt; [1] [ [[&lt;- #&gt; [3] [&lt;- $&lt;- #&gt; [5] aggregate anti_join #&gt; [7] arrange as.data.frame #&gt; [9] cbind coerce #&gt; [11] crs dbDataType #&gt; [13] dbWriteTable distance #&gt; [15] distinct dplyr_reconstruct #&gt; [17] drop_na duplicated #&gt; [19] ext extract #&gt; [21] filter full_join #&gt; [23] gather group_by #&gt; [25] group_split identify #&gt; [27] initialize inner_join #&gt; [29] left_join lines #&gt; [31] mask merge #&gt; [33] mutate nest #&gt; [35] pivot_longer pivot_wider #&gt; [37] plot points #&gt; [39] polys print #&gt; [41] rasterize rbind #&gt; [43] rename_with rename #&gt; [45] right_join rowwise #&gt; [47] sample_frac sample_n #&gt; [49] select semi_join #&gt; [51] separate_rows separate #&gt; [53] show slice #&gt; [55] slotsFromS3 spread #&gt; [57] st_agr st_agr&lt;- #&gt; [59] st_area st_as_s2 #&gt; [61] st_as_sf st_as_sfc #&gt; [63] st_bbox st_boundary #&gt; [65] st_break_antimeridian st_buffer #&gt; [67] st_cast st_centroid #&gt; [69] st_collection_extract st_concave_hull #&gt; [71] st_convex_hull st_coordinates #&gt; [73] st_crop st_crs #&gt; [75] st_crs&lt;- st_difference #&gt; [77] st_drop_geometry st_filter #&gt; [79] st_geometry st_geometry&lt;- #&gt; [81] st_inscribed_circle st_interpolate_aw #&gt; [83] st_intersection st_intersects #&gt; [85] st_is_valid st_is #&gt; [87] st_join st_line_merge #&gt; [89] st_m_range st_make_valid #&gt; [91] st_minimum_rotated_rectangle st_nearest_points #&gt; [93] st_node st_normalize #&gt; [95] st_point_on_surface st_polygonize #&gt; [97] st_precision st_reverse #&gt; [99] st_sample st_segmentize #&gt; [101] st_set_precision st_shift_longitude #&gt; [103] st_simplify st_snap #&gt; [105] st_sym_difference st_transform #&gt; [107] st_triangulate_constrained st_triangulate #&gt; [109] st_union st_voronoi #&gt; [111] st_wrap_dateline st_write #&gt; [113] st_z_range st_zm #&gt; [115] summarise svc #&gt; [117] transform transmute #&gt; [119] ungroup unite #&gt; [121] unnest vect #&gt; see &#39;?methods&#39; for accessing help and source code Here are some of the other highlights of sf you might be interested in: provides fast I/O, particularly relevant for large files spatial functions that rely on GEOS and GDAL and PROJ external libraries are directly linked into the package, so no need to load additional external packages (like in sp) sf objects can be plotted directly with ggplot sf directly reads from and writes to spatial databases such as PostGIS sf is compatible with the tidyvderse approach, (but see some pitfalls here) Note that sp and sf are not the only way spatial objects are conceptualized in R. Other spatial packages may use their own class definitions for spatial data (for example spatstat). There are packages specifically for the GeoJSON and for that reason are more lightweight, for example geojson Usually you can find functions that convert objects to and from these formats. Challenge Generate an sf point object. Create a matrix pts of random numbers with two columns and as many rows as you like. These are your points. Create a dataframe attrib_df with the same number of rows as your pts matrix and a column that holds an attribute. You can make up any attribute. Use the appropriate commands and pts an sf object with a gemoetry column of class sfc_POINT. Try to subset your spatial object using the attribute you have added and the way you are used to from regular data frames. How do you determine the bounding box of your spatial object? 1.2 Creating a spatial object from a lat/lon table Often in your research might have a spreadsheet that contains latitude, longitude and perhaps some attribute values. You know how to read the spreadsheet into a tabular format (tibble) with dplyr::read_table or dplyr::read_csv. We can then very easily convert the table into a spatial object in R. An sf object can be created from a data frame in the following way. We take advantage of the st_as_sf() function which converts any foreign object into an sf object. Similarly to above, it requires an argument coords, which in the case of point data needs to be a vector that specifies the data frame’s columns for the longitude and latitude (x,y) coordinates. my_sf_object &lt;- st_as_sf(myDataframe, coords) st_as_sf() creates a new object and leaves the original data frame untouched. We use read_csv() to read philly_homicides.csv into a tibble in R and name it philly_homicides_df. philly_homicides_df &lt;- read_csv(&quot;data/philly_homicides.csv&quot;) #&gt; Rows: 3883 Columns: 10 #&gt; ── Column specification ──────────────────────────────────────────────────────── #&gt; Delimiter: &quot;,&quot; #&gt; chr (3): SECTOR, LOCATION_BLOCK, TEXT_GENERAL_CODE #&gt; dbl (5): DC_DIST, UCR_GENERAL, OBJ_ID, POINT_X, POINT_Y #&gt; date (1): DISPATCH_DATE #&gt; time (1): DISPATCH_TIME #&gt; #&gt; ℹ Use `spec()` to retrieve the full column specification for this data. #&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. We convert the philly_homicides_df data frame into an sf object with st_as_sf() library(sf) philly_homicides_sf &lt;- st_as_sf(philly_homicides_df, coords = c(&quot;POINT_X&quot;, &quot;POINT_Y&quot;)) names(philly_homicides_sf) #&gt; [1] &quot;DC_DIST&quot; &quot;SECTOR&quot; &quot;DISPATCH_DATE&quot; #&gt; [4] &quot;DISPATCH_TIME&quot; &quot;LOCATION_BLOCK&quot; &quot;UCR_GENERAL&quot; #&gt; [7] &quot;OBJ_ID&quot; &quot;TEXT_GENERAL_CODE&quot; &quot;geometry&quot; Note the additional geometry list-column which now holds the simple feature collection with the coordinates of all the points. We now use st_crs() to check on the projection. st_crs(philly_homicides_sf) #&gt; Coordinate Reference System: NA To make it a complete geographical object we use st_set_crs() to assign the WGS84 projection, which has the EPSG code 4326: philly_homicides_sf %&gt;% st_set_crs(4326) #&gt; Simple feature collection with 3883 features and 8 fields #&gt; Geometry type: POINT #&gt; Dimension: XY #&gt; Bounding box: xmin: -75.26809 ymin: 39.87503 xmax: -74.95874 ymax: 40.13086 #&gt; Geodetic CRS: WGS 84 #&gt; # A tibble: 3,883 × 9 #&gt; DC_DIST SECTOR DISPATCH_DATE DISPATCH_TIME LOCATION_BLOCK UCR_GENERAL OBJ_ID #&gt; * &lt;dbl&gt; &lt;chr&gt; &lt;date&gt; &lt;time&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 22 1 2014-09-14 16:00 1800 BLOCK W M… 100 1 #&gt; 2 1 B 2006-01-14 00:00 2000 BLOCK MIF… 100 1 #&gt; 3 1 B 2006-04-01 16:05 S 22ND ST /SNY… 100 1 #&gt; 4 1 B 2006-05-10 11:13 2100 BLOCK MC … 100 1 #&gt; 5 1 E 2006-07-01 12:42 2100 BLOCK S H… 100 1 #&gt; 6 1 F 2006-07-09 19:13 1800 BLOCK SNY… 100 1 #&gt; 7 1 B 2006-07-10 23:20 1800 BLOCK S 2… 100 1 #&gt; 8 1 J 2006-07-16 01:26 2200 BLOCK JAC… 100 1 #&gt; 9 1 J 2006-10-03 20:37 2200 BLOCK S H… 100 1 #&gt; 10 1 A 2006-10-16 19:46 1900 BLOCK MC … 100 1 #&gt; # ℹ 3,873 more rows #&gt; # ℹ 2 more variables: TEXT_GENERAL_CODE &lt;chr&gt;, geometry &lt;POINT [°]&gt; st_crs(philly_homicides_sf) #&gt; Coordinate Reference System: NA Wow this is long. It is usually more helpful to just retrieve the proj4string: st_crs(philly_homicides_sf)$proj4string #&gt; [1] NA We will save this object as a shapefile on our hard drive for later use. (Note that by default st_write checks if the file already exists, and if so it will not overwrite it. If you need to force it to overwrite use the option delete_layer = TRUE.) st_write(philly_homicides_sf, &quot;data/PhillyHomicides&quot;, driver = &quot;ESRI Shapefile&quot;) # to force the save: st_write(philly_homicides_sf, &quot;data/PhillyHomicides&quot;, driver = &quot;ESRI Shapefile&quot;, delete_layer = TRUE) 1.3 Loading shape files into R sf relies on the powerful GDAL library, which is automatically linked in when loading sf. The GDAL provides the functionality to read and write spatial files of many formats. For shape files we can use st_read(), which simply takes the path of the directory with the shapefile as argument. # read in philly_sf &lt;- st_read(&quot;data/Philly/&quot;) #&gt; Reading layer `PhillyTotalPopHHinc&#39; from data source #&gt; `/Users/cengel/Anthro/R_Class/R_Workshops/R-spatial/data/Philly&#39; #&gt; using driver `ESRI Shapefile&#39; #&gt; Simple feature collection with 384 features and 17 fields #&gt; Geometry type: MULTIPOLYGON #&gt; Dimension: XY #&gt; Bounding box: xmin: 1739497 ymin: 457343.7 xmax: 1764030 ymax: 490544.9 #&gt; Projected CRS: Albers # take a look at what we&#39;ve got str(philly_sf) # note again the geometry column #&gt; Classes &#39;sf&#39; and &#39;data.frame&#39;: 384 obs. of 18 variables: #&gt; $ STATEFP10 : chr &quot;42&quot; &quot;42&quot; &quot;42&quot; &quot;42&quot; ... #&gt; $ COUNTYFP10: chr &quot;101&quot; &quot;101&quot; &quot;101&quot; &quot;101&quot; ... #&gt; $ TRACTCE10 : chr &quot;036301&quot; &quot;036400&quot; &quot;036600&quot; &quot;034803&quot; ... #&gt; $ GEOID10 : num 4.21e+10 4.21e+10 4.21e+10 4.21e+10 4.21e+10 ... #&gt; $ NAME10 : chr &quot;363.01&quot; &quot;364&quot; &quot;366&quot; &quot;348.03&quot; ... #&gt; $ NAMELSAD10: chr &quot;Census Tract 363.01&quot; &quot;Census Tract 364&quot; &quot;Census Tract 366&quot; &quot;Census Tract 348.03&quot; ... #&gt; $ MTFCC10 : chr &quot;G5020&quot; &quot;G5020&quot; &quot;G5020&quot; &quot;G5020&quot; ... #&gt; $ FUNCSTAT10: chr &quot;S&quot; &quot;S&quot; &quot;S&quot; &quot;S&quot; ... #&gt; $ ALAND10 : num 2322732 4501110 1004313 1271533 1016206 ... #&gt; $ AWATER10 : num 66075 8014 1426278 8021 0 ... #&gt; $ INTPTLAT10: chr &quot;+40.0895349&quot; &quot;+40.1127747&quot; &quot;+39.9470272&quot; &quot;+40.0619427&quot; ... #&gt; $ INTPTLON10: chr &quot;-074.9667387&quot; &quot;-074.9789137&quot; &quot;-075.1404472&quot; &quot;-075.0023705&quot; ... #&gt; $ GISJOIN : chr &quot;G4201010036301&quot; &quot;G4201010036400&quot; &quot;G4201010036600&quot; &quot;G4201010034803&quot; ... #&gt; $ Shape_area: num 2388806 4509124 2430591 1279556 1016207 ... #&gt; $ Shape_len : num 6851 10567 9257 4928 5920 ... #&gt; $ medHHinc : num 54569 NA 130139 56667 69981 ... #&gt; $ totalPop : num 3695 703 1643 4390 3807 ... #&gt; $ geometry :sfc_MULTIPOLYGON of length 384; first list element: List of 1 #&gt; ..$ :List of 1 #&gt; .. ..$ : num [1:55, 1:2] 1763647 1763473 1763366 1763378 1763321 ... #&gt; ..- attr(*, &quot;class&quot;)= chr [1:3] &quot;XY&quot; &quot;MULTIPOLYGON&quot; &quot;sfg&quot; #&gt; - attr(*, &quot;sf_column&quot;)= chr &quot;geometry&quot; #&gt; - attr(*, &quot;agr&quot;)= Factor w/ 3 levels &quot;constant&quot;,&quot;aggregate&quot;,..: NA NA NA NA NA NA NA NA NA NA ... #&gt; ..- attr(*, &quot;names&quot;)= chr [1:17] &quot;STATEFP10&quot; &quot;COUNTYFP10&quot; &quot;TRACTCE10&quot; &quot;GEOID10&quot; ... Two more words about the geometry column: Though it is not recommended, you can name this column any way you wish. Secondly, you can remove this column and revert to a regular, non-spatial data frame at any dime with st_drop_geometry(). The default plot of an sf object is a multi-plot of the first attributes, with a warning if not all can be plotted: plot(philly_sf) #&gt; Warning: plotting the first 10 out of 17 attributes; use max.plot = 17 to plot #&gt; all In order to only plot the polygon boundaries we need to directly use the geometry column. We use the st_geometry() function to extract it: plot(st_geometry(philly_sf)) Let’s add a subset of polygons with only the census tracts where the median houshold income (medHHinc) is more than $60,000. We can extract elements from an sf object based on attributes using the dplyr filter function (base R subsetting also works) and add the census tracts to the plot in a different color. plot(st_geometry(philly_sf)) philly_sf %&gt;% filter(medHHinc &gt; 60000) %&gt;% # filter for high income st_geometry() %&gt;% # extract the geometry for plotting plot(col=&quot;red&quot;, add=T) # add to the plot 1.4 Raster data in R Raster files, as you might know, have a more compact data structure than vectors. Because of their regular structure the coordinates do not need to be recorded for each pixel or cell in the rectangular extent. A raster is defined by: a CRS coordinates of its origin a distance or cell size in each direction a dimension or numbers of cells in each direction an array of cell values Given this structure, coordinates for any cell can be computed and don’t need to be stored. terra was first released in 2020 and now replaces the raster package which was first released in 2010. terra has greater functionality, is faster and easier to use. Figure 1.4: raster vs terra downloads on CRAN The terra package has functions for creating, reading, manipulating, and writing raster data. The package also implements raster algebra and many other functions for raster data manipulation. The package works with SpatRaster objects. The rast() function is used to create these objects. For example, to create a raster object from scratch we would do the following: library(terra) r &lt;- rast(nrows=20, ncols=20, # number of cells in x and y dimension xmin=0, xmax=360) # min and max x coordinates (left-right borders) r #&gt; class : SpatRaster #&gt; dimensions : 20, 20, 1 (nrow, ncol, nlyr) #&gt; resolution : 18, 9 (x, y) #&gt; extent : 0, 360, -90, 90 (xmin, xmax, ymin, ymax) #&gt; coord. ref. : lon/lat WGS 84 From the output above we know that: - the object is of class SpatRaster - its dimensions are 20x20 cells - it has one layer (band) - the extent of the raster - it has a CRS defined! If the crs argument is missing when creating the SpatRaster object, if the x coordinates are within -360 and 360 and the y coordinates are within -90 and 90, the WGS84 projection is used by default. Good to know. There are functions to look at individual properties of the raster object. For examle for the number of cells: ncell(r) #&gt; [1] 400 Or we can retrieve just the number of bands using the nlyr() function. nlyr(r) #&gt; [1] 1 We can also find out about the Coordinate Reference System (CRS) with the crs function. The default output looks a little messy: crs(r) #&gt; [1] &quot;GEOGCRS[\\&quot;WGS 84\\&quot;,\\n DATUM[\\&quot;World Geodetic System 1984\\&quot;,\\n ELLIPSOID[\\&quot;WGS 84\\&quot;,6378137,298.257223563,\\n LENGTHUNIT[\\&quot;metre\\&quot;,1]],\\n ID[\\&quot;EPSG\\&quot;,6326]],\\n PRIMEM[\\&quot;Greenwich\\&quot;,0,\\n ANGLEUNIT[\\&quot;degree\\&quot;,0.0174532925199433],\\n ID[\\&quot;EPSG\\&quot;,8901]],\\n CS[ellipsoidal,2],\\n AXIS[\\&quot;longitude\\&quot;,east,\\n ORDER[1],\\n ANGLEUNIT[\\&quot;degree\\&quot;,0.0174532925199433,\\n ID[\\&quot;EPSG\\&quot;,9122]]],\\n AXIS[\\&quot;latitude\\&quot;,north,\\n ORDER[2],\\n ANGLEUNIT[\\&quot;degree\\&quot;,0.0174532925199433,\\n ID[\\&quot;EPSG\\&quot;,9122]]]]&quot; We can make this easier to read by setting the proj argument: crs(r, proj = TRUE) # return the PROJ-string notation #&gt; [1] &quot;+proj=longlat +datum=WGS84 +no_defs&quot; Let’s try and plot this. plot(r) The canvas is empty! This is because even though we have a layer, the cells do not have any values. values(r) To add some random values to the cells we can take advantage of the ncells() function and do this: values(r) &lt;- runif(ncell(r)) r #&gt; class : SpatRaster #&gt; dimensions : 20, 20, 1 (nrow, ncol, nlyr) #&gt; resolution : 18, 9 (x, y) #&gt; extent : 0, 360, -90, 90 (xmin, xmax, ymin, ymax) #&gt; coord. ref. : lon/lat WGS 84 #&gt; source(s) : memory #&gt; name : lyr.1 #&gt; min value : 0.001531723 #&gt; max value : 0.999906505 In addition to the output above, we now see: - the source, which indicates where the cell values are stored (here they are in memory) - the range of the cell values (min value adn max value) now added. - the name, of the layer which is by default lyr.1. This now plots successfully: plot(r) (The rasterVis package provides a set of methods for enhanced visualization and interaction for more advanced plotting of raster objects.) SpatRaster objects can also be created from a matrix. class(volcano) #&gt; [1] &quot;matrix&quot; &quot;array&quot; volcano.r &lt;- rast(volcano) class(volcano.r) #&gt; [1] &quot;SpatRaster&quot; #&gt; attr(,&quot;package&quot;) #&gt; [1] &quot;terra&quot; We also use the rast() function to read in a raster file. This raster is generated as part of the NEON Harvard Forest field site. HARV &lt;- rast(&quot;data/HARV_RGB_Ortho.tif&quot;) Typing the name of the object will give us what’s in there: HARV #&gt; class : SpatRaster #&gt; dimensions : 2317, 3073, 3 (nrow, ncol, nlyr) #&gt; resolution : 0.25, 0.25 (x, y) #&gt; extent : 731998.5, 732766.8, 4712956, 4713536 (xmin, xmax, ymin, ymax) #&gt; coord. ref. : WGS 84 / UTM zone 18N (EPSG:32618) #&gt; source : HARV_RGB_Ortho.tif #&gt; names : HARV_RGB_Ortho_1, HARV_RGB_Ortho_2, HARV_RGB_Ortho_3 #&gt; min values : 0, 0, 0 #&gt; max values : 255, 255, 255 Challenge Based on the output above answer the following questions: How many bands? What are the names of the bands)? Where are the cell values stored? What is the CRS? We can plot the object like this: plot(HARV) Or to plot a single band: plot(HARV, 3) We can also use the rast() function to import one single band: HARV_Band2 &lt;- rast(&quot;data/HARV_RGB_Ortho.tif&quot;, lyrs = 2) plot(HARV_Band2) Let’s now explore the distribution of values contained within our raster using the hist() function which produces a histogram. Histograms are often useful in identifying outliers and bad data values in our raster data. hist(HARV) #&gt; Warning: [hist] a sample of 14% of the cells was used #&gt; Warning: [hist] a sample of 14% of the cells was used #&gt; Warning: [hist] a sample of 14% of the cells was used Notice that a warning message is produced when R creates the histogram. By default the maximum cells processed per band is 1,000,000. This maximum value is to ensure processing efficiency as our data become larger. We can force the hist function to use all cell values. ncell(HARV) #&gt; [1] 7120141 hist(HARV, maxcell = ncell(HARV)) At times it may be useful to explore raster metadata before loading them into R. This can be done with the function describe() describe(&quot;data/HARV_RGB_Ortho.tif&quot;) #&gt; [1] &quot;Driver: GTiff/GeoTIFF&quot; #&gt; [2] &quot;Files: data/HARV_RGB_Ortho.tif&quot; #&gt; [3] &quot;Size is 3073, 2317&quot; #&gt; [4] &quot;Coordinate System is:&quot; #&gt; [5] &quot;PROJCRS[\\&quot;WGS 84 / UTM zone 18N\\&quot;,&quot; #&gt; [6] &quot; BASEGEOGCRS[\\&quot;WGS 84\\&quot;,&quot; #&gt; [7] &quot; DATUM[\\&quot;World Geodetic System 1984\\&quot;,&quot; #&gt; [8] &quot; ELLIPSOID[\\&quot;WGS 84\\&quot;,6378137,298.257223563,&quot; #&gt; [9] &quot; LENGTHUNIT[\\&quot;metre\\&quot;,1]]],&quot; #&gt; [10] &quot; PRIMEM[\\&quot;Greenwich\\&quot;,0,&quot; #&gt; [11] &quot; ANGLEUNIT[\\&quot;degree\\&quot;,0.0174532925199433]],&quot; #&gt; [12] &quot; ID[\\&quot;EPSG\\&quot;,4326]],&quot; #&gt; [13] &quot; CONVERSION[\\&quot;UTM zone 18N\\&quot;,&quot; #&gt; [14] &quot; METHOD[\\&quot;Transverse Mercator\\&quot;,&quot; #&gt; [15] &quot; ID[\\&quot;EPSG\\&quot;,9807]],&quot; #&gt; [16] &quot; PARAMETER[\\&quot;Latitude of natural origin\\&quot;,0,&quot; #&gt; [17] &quot; ANGLEUNIT[\\&quot;degree\\&quot;,0.0174532925199433],&quot; #&gt; [18] &quot; ID[\\&quot;EPSG\\&quot;,8801]],&quot; #&gt; [19] &quot; PARAMETER[\\&quot;Longitude of natural origin\\&quot;,-75,&quot; #&gt; [20] &quot; ANGLEUNIT[\\&quot;degree\\&quot;,0.0174532925199433],&quot; #&gt; [21] &quot; ID[\\&quot;EPSG\\&quot;,8802]],&quot; #&gt; [22] &quot; PARAMETER[\\&quot;Scale factor at natural origin\\&quot;,0.9996,&quot; #&gt; [23] &quot; SCALEUNIT[\\&quot;unity\\&quot;,1],&quot; #&gt; [24] &quot; ID[\\&quot;EPSG\\&quot;,8805]],&quot; #&gt; [25] &quot; PARAMETER[\\&quot;False easting\\&quot;,500000,&quot; #&gt; [26] &quot; LENGTHUNIT[\\&quot;metre\\&quot;,1],&quot; #&gt; [27] &quot; ID[\\&quot;EPSG\\&quot;,8806]],&quot; #&gt; [28] &quot; PARAMETER[\\&quot;False northing\\&quot;,0,&quot; #&gt; [29] &quot; LENGTHUNIT[\\&quot;metre\\&quot;,1],&quot; #&gt; [30] &quot; ID[\\&quot;EPSG\\&quot;,8807]]],&quot; #&gt; [31] &quot; CS[Cartesian,2],&quot; #&gt; [32] &quot; AXIS[\\&quot;(E)\\&quot;,east,&quot; #&gt; [33] &quot; ORDER[1],&quot; #&gt; [34] &quot; LENGTHUNIT[\\&quot;metre\\&quot;,1]],&quot; #&gt; [35] &quot; AXIS[\\&quot;(N)\\&quot;,north,&quot; #&gt; [36] &quot; ORDER[2],&quot; #&gt; [37] &quot; LENGTHUNIT[\\&quot;metre\\&quot;,1]],&quot; #&gt; [38] &quot; USAGE[&quot; #&gt; [39] &quot; SCOPE[\\&quot;Engineering survey, topographic mapping.\\&quot;],&quot; #&gt; [40] &quot; AREA[\\&quot;Between 78°W and 72°W, northern hemisphere between equator and 84°N, onshore and offshore. Bahamas. Canada - Nunavut; Ontario; Quebec. Colombia. Cuba. Ecuador. Greenland. Haiti. Jamaica. Panama. Turks and Caicos Islands. United States (USA). Venezuela.\\&quot;],&quot; #&gt; [41] &quot; BBOX[0,-78,84,-72]],&quot; #&gt; [42] &quot; ID[\\&quot;EPSG\\&quot;,32618]]&quot; #&gt; [43] &quot;Data axis to CRS axis mapping: 1,2&quot; #&gt; [44] &quot;Origin = (731998.500000000000000,4713535.500000000000000)&quot; #&gt; [45] &quot;Pixel Size = (0.250000000000000,-0.250000000000000)&quot; #&gt; [46] &quot;Metadata:&quot; #&gt; [47] &quot; AREA_OR_POINT=Area&quot; #&gt; [48] &quot;Image Structure Metadata:&quot; #&gt; [49] &quot; COMPRESSION=LZW&quot; #&gt; [50] &quot; INTERLEAVE=PIXEL&quot; #&gt; [51] &quot;Corner Coordinates:&quot; #&gt; [52] &quot;Upper Left ( 731998.500, 4713535.500) ( 72d10&#39;29.27\\&quot;W, 42d32&#39;21.80\\&quot;N)&quot; #&gt; [53] &quot;Lower Left ( 731998.500, 4712956.250) ( 72d10&#39;30.11\\&quot;W, 42d32&#39; 3.04\\&quot;N)&quot; #&gt; [54] &quot;Upper Right ( 732766.750, 4713535.500) ( 72d 9&#39;55.63\\&quot;W, 42d32&#39;20.97\\&quot;N)&quot; #&gt; [55] &quot;Lower Right ( 732766.750, 4712956.250) ( 72d 9&#39;56.48\\&quot;W, 42d32&#39; 2.21\\&quot;N)&quot; #&gt; [56] &quot;Center ( 732382.625, 4713245.875) ( 72d10&#39;12.87\\&quot;W, 42d32&#39;12.00\\&quot;N)&quot; #&gt; [57] &quot;Band 1 Block=3073x1 Type=Float64, ColorInterp=Gray&quot; #&gt; [58] &quot; Min=0.000 Max=255.000 &quot; #&gt; [59] &quot; Minimum=0.000, Maximum=255.000, Mean=nan, StdDev=nan&quot; #&gt; [60] &quot; NoData Value=-1.7e+308&quot; #&gt; [61] &quot; Metadata:&quot; #&gt; [62] &quot; STATISTICS_MAXIMUM=255&quot; #&gt; [63] &quot; STATISTICS_MEAN=nan&quot; #&gt; [64] &quot; STATISTICS_MINIMUM=0&quot; #&gt; [65] &quot; STATISTICS_STDDEV=nan&quot; #&gt; [66] &quot;Band 2 Block=3073x1 Type=Float64, ColorInterp=Undefined&quot; #&gt; [67] &quot; Min=0.000 Max=255.000 &quot; #&gt; [68] &quot; Minimum=0.000, Maximum=255.000, Mean=nan, StdDev=nan&quot; #&gt; [69] &quot; NoData Value=-1.7e+308&quot; #&gt; [70] &quot; Metadata:&quot; #&gt; [71] &quot; STATISTICS_MAXIMUM=255&quot; #&gt; [72] &quot; STATISTICS_MEAN=nan&quot; #&gt; [73] &quot; STATISTICS_MINIMUM=0&quot; #&gt; [74] &quot; STATISTICS_STDDEV=nan&quot; #&gt; [75] &quot;Band 3 Block=3073x1 Type=Float64, ColorInterp=Undefined&quot; #&gt; [76] &quot; Min=0.000 Max=255.000 &quot; #&gt; [77] &quot; Minimum=0.000, Maximum=255.000, Mean=nan, StdDev=nan&quot; #&gt; [78] &quot; NoData Value=-1.7e+308&quot; #&gt; [79] &quot; Metadata:&quot; #&gt; [80] &quot; STATISTICS_MAXIMUM=255&quot; #&gt; [81] &quot; STATISTICS_MEAN=nan&quot; #&gt; [82] &quot; STATISTICS_MINIMUM=0&quot; #&gt; [83] &quot; STATISTICS_STDDEV=nan&quot; For the many functions available for working with such an object see: methods(class=class(HARV)) #&gt; [1] ! [ [[ #&gt; [4] [[&lt;- [&lt;- %in% #&gt; [7] $ $&lt;- activeCat #&gt; [10] activeCat&lt;- add&lt;- addCats #&gt; [13] adjacent aggregate align #&gt; [16] all.equal allNA animate #&gt; [19] anyNA app approximate #&gt; [22] area Arith as.array #&gt; [25] as.bool as.character as.contour #&gt; [28] as.data.frame as.factor as.int #&gt; [31] as.integer as.lines as.list #&gt; [34] as.logical as.matrix as.numeric #&gt; [37] as.points as.polygons as.raster #&gt; [40] atan_2 atan2 autocor #&gt; [43] barplot blocks boundaries #&gt; [46] boxplot buffer c #&gt; [49] catalyze categories cats #&gt; [52] cellFromRowCol cellFromRowColCombine cellFromXY #&gt; [55] cells cellSize clamp_ts #&gt; [58] clamp classify click #&gt; [61] coerce colFromCell colFromX #&gt; [64] colorize coltab coltab&lt;- #&gt; [67] Compare compare compareGeom #&gt; [70] concats contour costDist #&gt; [73] countNA cover crds #&gt; [76] crop crosstab crs #&gt; [79] crs&lt;- datatype deepcopy #&gt; [82] density depth depth&lt;- #&gt; [85] diff dim dim&lt;- #&gt; [88] direction disagg distance #&gt; [91] droplevels expanse ext #&gt; [94] ext&lt;- extend extract #&gt; [97] extractRange fillTime flip #&gt; [100] focal focal3D focalCor #&gt; [103] focalCpp focalPairs focalReg #&gt; [106] focalValues freq getTileExtents #&gt; [109] global gridDist gridDistance #&gt; [112] has.colors has.RGB has.time #&gt; [115] hasMinMax hasValues head #&gt; [118] hist identical ifel #&gt; [121] image init inMemory #&gt; [124] inset interpIDW interpNear #&gt; [127] interpolate intersect is.bool #&gt; [130] is.factor is.finite is.infinite #&gt; [133] is.int is.lonlat is.na #&gt; [136] is.nan is.related is.rotated #&gt; [139] isFALSE isTRUE k_means #&gt; [142] lapp layerCor levels #&gt; [145] levels&lt;- linearUnits lines #&gt; [148] log Logic logic #&gt; [151] longnames longnames&lt;- makeTiles #&gt; [154] mask match math #&gt; [157] Math Math2 mean #&gt; [160] median merge meta #&gt; [163] metags metags&lt;- minmax #&gt; [166] modal mosaic NAflag #&gt; [169] NAflag&lt;- names names&lt;- #&gt; [172] ncell ncol ncol&lt;- #&gt; [175] nlyr nlyr&lt;- noNA #&gt; [178] not.na nrow nrow&lt;- #&gt; [181] nsrc origin origin&lt;- #&gt; [184] pairs panel patches #&gt; [187] persp plet plot #&gt; [190] plotRGB points polys #&gt; [193] prcomp predict princomp #&gt; [196] project quantile rangeFill #&gt; [199] rapp rast rasterize #&gt; [202] rasterizeGeom rasterizeWin rcl #&gt; [205] readStart readStop readValues #&gt; [208] rectify regress relate #&gt; [211] rep res res&lt;- #&gt; [214] resample rescale rev #&gt; [217] RGB RGB&lt;- roll #&gt; [220] rotate rowColCombine rowColFromCell #&gt; [223] rowFromCell rowFromY sapp #&gt; [226] saveRDS scale scoff #&gt; [229] scoff&lt;- sds segregate #&gt; [232] sel selectHighest selectRange #&gt; [235] serialize set.cats set.crs #&gt; [238] set.ext set.names set.RGB #&gt; [241] set.values setMinMax setValues #&gt; [244] shift show sieve #&gt; [247] size sort sources #&gt; [250] spatSample split sprc #&gt; [253] st_bbox st_crs stdev #&gt; [256] str stretch subset #&gt; [259] subst summary Summary #&gt; [262] t tail tapp #&gt; [265] terrain text tighten #&gt; [268] time time&lt;- timeInfo #&gt; [271] trans trim unique #&gt; [274] units units&lt;- update #&gt; [277] values values&lt;- varnames #&gt; [280] varnames&lt;- viewshed weighted.mean #&gt; [283] where.max where.min which.lyr #&gt; [286] which.max which.min window #&gt; [289] window&lt;- wrap wrapCache #&gt; [292] writeCDF writeRaster writeStart #&gt; [295] writeStop writeValues xapp #&gt; [298] xFromCell xFromCol xmax #&gt; [301] xmax&lt;- xmin xmin&lt;- #&gt; [304] xres xyFromCell yFromCell #&gt; [307] yFromRow ymax ymax&lt;- #&gt; [310] ymin ymin&lt;- yres #&gt; [313] zonal zoom #&gt; see &#39;?methods&#39; for accessing help and source code E. Pebesma &amp; R. Bivand (2016)Spatial data in R: simple features and future perspectives↩︎ "],["spatialops.html", "Chapter 2 Spatial data manipulation in R 2.1 Attribute Join 2.2 Topological Subsetting: Select Polygons by Location 2.3 Reprojecting 2.4 Spatial Aggregation: Points in Polygons 2.5 Raster calculations with terra", " Chapter 2 Spatial data manipulation in R Learning Objectives Join attribute data to a polygon vector file Reproject a vector file Select polygons of a vector by location There are a wide variety of spatial, topological, and attribute data operations you can perform with R. Lovelace et al’s recent publication2 goes into great depth about this and is highly recommended. In this section we will look at a few examples for libraries and commands that allow us to process spatial data in R and perform a few commonly used operations. 2.1 Attribute Join An attribute join on vector data brings tabular data into a geographic context. It refers to the process of joining data in tabular format to data in a format that holds the geometries (polygon, line, or point). If you have done attribute joins of shapefiles in GIS software like ArcGIS or QGis you know that you need a unique identifier in both the attribute table of the shapefile and the table to be joined. First we will load the CSV table PhiladelphiaEduAttain.csv into a dataframe in R and name it ph_edu. ph_edu &lt;- read_csv(&quot;data/PhiladelphiaEduAttain.csv&quot;) #&gt; Rows: 384 Columns: 13 #&gt; ── Column specification ──────────────────────────────────────────────────────── #&gt; Delimiter: &quot;,&quot; #&gt; chr (1): NAME #&gt; dbl (12): GEOID, fem_bachelor, fem_doctorate, fem_highschool, fem_noschool, ... #&gt; #&gt; ℹ Use `spec()` to retrieve the full column specification for this data. #&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. names(ph_edu) If you don’t have the object still loaded read the the PhillyTotalPopHHinc shapefile into an object named philly_sf. Check out the column names of philly_sf and of ph_edu to determine which one might contain the unique identifier for the join. # if you need to read in again: # philly_sf &lt;- st_read(&quot;data/Philly/&quot;) names(philly_sf) To join the ph_edu data frame with philly_sf we can use merge like this: philly_sf_merged &lt;- left_join(philly_sf, ph_edu, by = c(&quot;GEOID10&quot; = &quot;GEOID&quot;)) names(philly_sf_merged) #&gt; [1] &quot;STATEFP10&quot; &quot;COUNTYFP10&quot; &quot;TRACTCE10&quot; &quot;GEOID10&quot; #&gt; [5] &quot;NAME10&quot; &quot;NAMELSAD10&quot; &quot;MTFCC10&quot; &quot;FUNCSTAT10&quot; #&gt; [9] &quot;ALAND10&quot; &quot;AWATER10&quot; &quot;INTPTLAT10&quot; &quot;INTPTLON10&quot; #&gt; [13] &quot;GISJOIN&quot; &quot;Shape_area&quot; &quot;Shape_len&quot; &quot;medHHinc&quot; #&gt; [17] &quot;totalPop&quot; &quot;NAME&quot; &quot;fem_bachelor&quot; &quot;fem_doctorate&quot; #&gt; [21] &quot;fem_highschool&quot; &quot;fem_noschool&quot; &quot;fem_ovr_25&quot; &quot;male_bachelor&quot; #&gt; [25] &quot;male_doctorate&quot; &quot;male_highschool&quot; &quot;male_noschool&quot; &quot;male_ovr_25&quot; #&gt; [29] &quot;pop_ovr_25&quot; &quot;geometry&quot; We see the new attribute columns added, as well as the geometry column. 2.2 Topological Subsetting: Select Polygons by Location For the next example our goal is to select all Philadelphia census tracts within a range of 2 kilometers from the city center. Think about this for a moment – what might be the steps you’d follow? ## How about: # 1. Get the census tract polygons. # 2. Find the Philadelphia city center coordinates. # 3. Create a buffer around the city center point. # 4. Select all census tract polygons that intersect with the center buffer We will use philly_sf for the census tract polygons. In addition, we need to create a sf Point object with the Philadelphia city center coordinates: \\[x = 1750160\\] \\[y = 467499.9\\] These coordinates are also in the USA Contiguous Albers Equal Area Conic projected CRS, which is the same as CRS as philly_sf. With this information, we create a object that holds the coordinates of the city center. Since we don’t have attributes we will just create it as a simple feature collection, scf. # if you need to read in again: # philly_sf &lt;- st_read(&quot;data/Philly/&quot;, quiet = T) # make a simple feature point with CRS philly_ctr_sfc &lt;- st_sfc(st_point(c(1750160, 467499.9)), crs = st_crs(philly_sf)) For the spatial operations we can recur to the suite of geometric operations that come with the sf package. We create a 2km buffer around the city center point: philly_buf &lt;- st_buffer(philly_ctr_sfc, 2000) Ok. Now we can use that buffer to select all census tract polygons that intersect with the center buffer. In order to determine the polygons we use st_intersects, a geometric binary which returns a vector of indices of the polygons that intersect with the buffer. philly_intersects &lt;- st_intersects(philly_buf, philly_sf) philly_intersects #&gt; Sparse geometry binary predicate list of length 1, where the predicate #&gt; was `intersects&#39; #&gt; 1: 3, 10, 11, 12, 13, 19, 20, 21, 50, 51, ... We have created a sgbp object, which is a “Sparse Geometry Binary Predicate”. It is a so called sparse matrix, which is a list with integer vectors only holding the indices for each polygon that intersects. In our case we only have one vector, because we only intersect with one buffer polygon, so we can extract this first vector with philly_buf_intersects[[1]] and use it for subsetting: philly_sel&lt;- philly_sf[philly_intersects[[1]],] # plot plot(st_geometry(philly_sf), border=&quot;#aaaaaa&quot;, main=&quot;Census tracts that overlap with 2km buffer around city center&quot;) plot(st_geometry(philly_sel), add=T, col=&quot;red&quot;) plot(st_geometry(philly_buf), add=T, lwd = 2) Note the difference to st_intersection, which performs a geometric operation and creates a new sf object which cuts out the area of the buffer from the polygons like cookie a cutter: philly_intersection &lt;- st_intersection(philly_buf, philly_sf) philly_intersection #&gt; Geometry set for 46 features #&gt; Geometry type: GEOMETRY #&gt; Dimension: XY #&gt; Bounding box: xmin: 1748160 ymin: 465499.9 xmax: 1752160 ymax: 469499.9 #&gt; Projected CRS: Albers #&gt; First 5 geometries: #&gt; POLYGON ((1752157 467395.2, 1752153 467339.7, 1... #&gt; POLYGON ((1752149 467290.8, 1752135 467187, 175... #&gt; POLYGON ((1751347 466573.5, 1751321 467037.6, 1... #&gt; POLYGON ((1750298 467616.7, 1750148 467615.2, 1... #&gt; POLYGON ((1748853 467255, 1748874 467605.3, 174... plot(st_geometry(philly_sf), border=&quot;#aaaaaa&quot;, main=&quot;Census tracts around city center, clipped by 2km buffer &quot;) plot(philly_intersection, add=T, lwd = 2, border = &quot;red&quot;) 2.3 Reprojecting Occasionally you may have to change the coordinates of your spatial object into a new Coordinate Reference System (CRS). Functions to transform, or reproject spatial objects typically take the following two arguments: the spatial object to reproject a CRS object with the new projection definition You can reproject a sf object with st_transform() a SpatRaster object with project() The perhaps trickiest part here is to determine the definition of the projection, which needs to be a character string in proj4 format. You can look it up online. For example for UTM zone 33N (EPSG:32633) the string would be: +proj=utm +zone=33 +ellps=WGS84 +datum=WGS84 +units=m +no_defs You can retrieve the CRS: from an sf object with st_crs() from a SpatRaster object with crs() Let us go back to the \"PhillyHomicides\" shapefile we exported earlier. Let’s read it back in and reproject it so it matches the projection of the Philadelphia Census tracts. Now let us check the CRS for both files. #If you need to read the file back in: #philly_homicides_sf &lt;- st_read(&quot;data/PhillyHomicides/&quot;) st_crs(philly_sf)$proj4string #&gt; [1] &quot;+proj=aea +lat_0=37.5 +lon_0=-96 +lat_1=29.5 +lat_2=45.5 +x_0=0 +y_0=0 +ellps=GRS80 +units=m +no_defs&quot; st_crs(philly_homicides_sf)$proj4string #&gt; [1] &quot;+proj=longlat +datum=WGS84 +no_defs&quot; We see that the CRS are different: we have +proj=aea... and +proj=longlat.... AEA refers to USA Contiguous Albers Equal Area Conic which is a projected coordinate system with numeric units. We will need this below for our spatial operations, so we will make sure both files are in that same CRS. We use st_transform and assign the result to a new object. Note how we also use str_crs to extract the projection definition from philly_sf, so we don’t have to type it out. philly_homicides_sf_aea &lt;- st_transform(philly_homicides_sf, st_crs(philly_sf)) We can use the range() command from the R base package to compare the coordinates before and after reprojection and confirm that we actually have transformed them. range() returns the min and max value of a vector of numbers. range(st_coordinates(philly_homicides_sf)) #&gt; [1] -75.26809 40.13086 range(st_coordinates(philly_homicides_sf_aea)) #&gt; [1] 457489.7 1763671.8 We can also compare them visually with: par(mfrow=c(1,2)) plot(st_geometry(philly_homicides_sf), axes=TRUE, main = &quot;before transform - latlon&quot;) plot(st_geometry(philly_homicides_sf_aea), axes=TRUE, main = &quot;after transform - aea&quot;) Lastly, let us save the reprojected file as PhillyHomicides_aea shapefile, as we will use it later on. st_write(philly_homicides_sf_aea, &quot;data/PhillyHomicides_aea&quot;, driver = &quot;ESRI Shapefile&quot;) 2.3.1 Raster reprojection Here is what it would look like to reproject the HARV raster used earlier to a WGS84 projection. We see that see that the original projection is in UTM. # if you need to load again: #HARV &lt;- raster(&quot;data/HARV_RGB_Ortho.tif&quot;) crs(HARV, proj = TRUE) #&gt; [1] &quot;+proj=utm +zone=18 +datum=WGS84 +units=m +no_defs&quot; HARV_WGS84 &lt;- project(HARV, &quot;+init=epsg:4326&quot;) crs(HARV, proj = TRUE) #&gt; [1] &quot;+proj=utm +zone=18 +datum=WGS84 +units=m +no_defs&quot; Let’s look at the coordinates to see the effect: ext(HARV) #&gt; SpatExtent : 731998.5, 732766.75, 4712956.25, 4713535.5 (xmin, xmax, ymin, ymax) ext(HARV_WGS84) #&gt; SpatExtent : -72.1750316832584, -72.1654516638594, 42.5339461813323, 42.5393881837189 (xmin, xmax, ymin, ymax) Due to the reprojection the number of cells has also changed: ncell(HARV) #&gt; [1] 7120141 ncell(HARV_WGS84) #&gt; [1] 6859650 And here is the visual proof: plot(HARV, main = &quot;before transform - UTM&quot;) plot(HARV_WGS84, main = &quot;after transform - WGS84&quot;) 2.4 Spatial Aggregation: Points in Polygons Now that we have both homicides and census tracts in the same projection we will forge ahead and ask for the density of homicides for each census tract in Philadelphia: \\(\\frac{{homicides}}{area}\\) To achieve this this we join the points of homicide incidence to the census tract polygon and count them up for each polygon. You might be familiar with this operation from other GIS packages. We will use piping and build up our object in the following way. First we calculate the area for each tract. We use the st_area function on the geometry column and add the result. philly_sf %&gt;% mutate(tract_area = st_area(geometry)) %&gt;% head() Next, we use st_join to perform a spatial join with the points: philly_sf %&gt;% mutate(tract_area = st_area(geometry)) %&gt;% st_join(philly_homicides_sf_aea) %&gt;% head() Now we can group by a variable that uiquely identifies the census tracts, (we choose GEOID10) and use summarize to count the points for each tract and calculate the homicide rate. Since our units are in sq meter we multiply by by 1000000 to get sq km. We also need to carry over the area, which I do using unique. We also assign the output to a new object philly_crimes_sf. philly_crimes_sf &lt;- philly_sf %&gt;% mutate(tract_area = st_area(geometry)) %&gt;% st_join(philly_homicides_sf_aea) %&gt;% group_by(GEOID10) %&gt;% summarize(n_homic = n(), tract_area = unique(tract_area), homic_rate = as.numeric(1e6 * (n_homic/tract_area))) Finally, we write this out for later: st_write(philly_crimes_sf, &quot;data/PhillyCrimerate&quot;, driver = &quot;ESRI Shapefile&quot;) 2.5 Raster calculations with terra We often want to perform calculations on two or more rasters to create a new output raster. For example, if we are interested in mapping the heights of trees across an entire field site, we might want to calculate the difference between the Digital Surface Model (DSM, tops of trees) and the Digital Terrain Model (DTM, ground level). The resulting dataset is referred to as a Canopy Height Model (CHM) and represents the actual height of trees, buildings, etc. with the influence of ground elevation removed. First let’s read in the two datasets. HARV_DTM &lt;- rast(&quot;data/HARV_dtmCrop.tif&quot;) HARV_DSM &lt;- rast(&quot;data/HARV_dsmCrop.tif&quot;) Now we can subtract the DTM from the DSM to create a Canopy Height Model. It will for each CHM pixel calculate the difference of the respective DTM and DSM pixels. HARV_CHM &lt;- HARV_DSM - HARV_DTM par(mfrow = c(1, 2)) plot(HARV_CHM) hist(HARV_CHM) #&gt; Warning: [hist] a sample of 43% of the cells was used (of which 0% was NA) This works fine for the small rasters in this tutorial. However, the calculation above becomes less efficient when computations are more complex or file sizes become large. Thet terra package contains a function called lapp()function to make processing more efficient. It takes two or more rasters and applies a function to them. The generic syntax is: outputRaster &lt;- lapp(x, fun) where x is a SpatRasterDataset and fun is a custom function for the operation you want to perform. CHM_ov_HARV &lt;- lapp(sds(list(HARV_DSM, HARV_DTM)), fun = function(r1, r2) { return( r1 - r2) }) As arguments for our lapp operation we use the sds() function and provide it with the list of rasters that we want to operate on. As custom function we provide the function with two arguments (r1 and r1) that subtracts the second (r2) from the first (r1) and returns the difference. The output of lapp is a SpatRaster and we assign it to a new variable CHM_ov_HARV. par(mfrow = c(1, 2)) plot(CHM_ov_HARV) hist(CHM_ov_HARV) #&gt; Warning: [hist] a sample of 43% of the cells was used (of which 0% was NA) Lovelace, R., Nowosad, J., &amp; Muenchow, J. (2024). Geocomputation with R. CRC Press.↩︎ "],["mapping.html", "Chapter 3 Making Maps in R 3.1 Choropleth Mapping with ggplot2 3.2 Raster and ggplot 3.3 Choropleth with tmap 3.4 Raster with tmap 3.5 Web mapping with leaflet", " Chapter 3 Making Maps in R Learning Objectives plot an sf object create a choropleth map with ggplot add a basemap with ggmap use RColorBrewer to improve legend colors use classIntto improve legend breaks create a choropleth map with tmap create an interactive map with leaflet customize a leaflet map with popups and layer controls In the preceding examples we have used the base plot command to take a quick look at our spatial objects. In this section we will explore several alternatives to map spatial data with R. For more packages see the “Visualisation” section of the CRAN Task View. 3.1 Choropleth Mapping with ggplot2 ggplot2 is a widely used and powerful plotting library for R. It is not specifically geared towards mapping, it is possible to create quite nice maps. For an introduction to ggplot check out this site for more pointers. ggplot can plot sf objects directly by using the geom geom_sf. So all we have to do is: library(ggplot2) ggplot(philly_crimes_sf) + geom_sf(aes(fill=homic_rate)) Homicide rate is a continuous variable and is plotted by ggplot as such. If we wanted to plot our map as a ‘true’ choropleth map we need to convert our continouse variable into a categoriacal one, according to whichever brackets we want to use. This requires two steps: Determine the quantile breaks. Add a categorical variable to the object which assigns each continious vaule to a bracket. We will use the classInt package to explicitly determine the breaks. library(classInt) # get quantile breaks. Add .00001 offset to catch the lowest value breaks_qt &lt;- classIntervals(c(min(philly_crimes_sf$homic_rate) - .00001, philly_crimes_sf$homic_rate), n = 7, style = &quot;quantile&quot;) str(breaks_qt) #&gt; List of 2 #&gt; $ var : num [1:385] 0.3 14.2 10.5 12.7 38.9 ... #&gt; $ brks: num [1:8] 0.3 1.86 4.81 8.5 16.14 ... #&gt; - attr(*, &quot;style&quot;)= chr &quot;quantile&quot; #&gt; - attr(*, &quot;nobs&quot;)= int 385 #&gt; - attr(*, &quot;call&quot;)= language classIntervals(var = c(min(philly_crimes_sf$homic_rate) - 1e-05, philly_crimes_sf$homic_rate), n = 7, style = &quot;quantile&quot;) #&gt; - attr(*, &quot;intervalClosure&quot;)= chr &quot;left&quot; #&gt; - attr(*, &quot;class&quot;)= chr &quot;classIntervals&quot; Ok. We can retrieve the breaks with breaks$brks. We use cut to divicde homic_rate into intervals and code them according to which interval they are in. Lastly, we can use scale_fill_brewer and add our color palette. philly_crimes_sf &lt;- mutate(philly_crimes_sf, homic_rate_cat = cut(homic_rate, breaks_qt$brks)) ggplot(philly_crimes_sf) + geom_sf(aes(fill=homic_rate_cat)) + scale_fill_brewer(palette = &quot;OrRd&quot;) 3.2 Raster and ggplot To visualize raster data using ggplot2, we will use the raster with the values for the digital terrain model (DTM). If you need to read it in again: HARV_DTM &lt;- rast(&quot;data/HARV_dtmCrop.tif&quot;) Before using ggplot we need to convert this to a dataframe. The terra package has an built-in function for conversion to a plotable dataframe. HARV_DTM_df &lt;- as.data.frame(HARV_DTM, xy = TRUE) str(HARV_DTM_df) #&gt; &#39;data.frame&#39;: 2319798 obs. of 3 variables: #&gt; $ x : num 731454 731454 731456 731456 731458 ... #&gt; $ y : num 4713838 4713838 4713838 4713838 4713838 ... #&gt; $ HARV_dtmCrop: num 389 390 389 389 389 ... We can now use ggplot() to plot this data frame. We will set the color scale to scale_fill_viridis_c which is a color-blindness friendly color scale. Here is more about the viridis color maps. We will also use the coord_fixed() function with the default, ratio = 1, which ensures that one unit on the x-axis is the same length as one unit on the y-axis. ggplot() + geom_raster(data = HARV_DTM_df , aes(x = x, y = y, fill = HARV_dtmCrop)) + scale_fill_viridis_c() + coord_fixed() 3.3 Choropleth with tmap tmap is specifically designed to make creation of thematic maps more convenient. It borrows from the ggplot syntax and takes care of a lot of the styling and aesthetics. This reduces our amount of code significantly. We only need: tm_shape() where we provide the sf object tm_polygons() where we set the attribute variable to map, the break style, and a title. library(tmap) tm_shape(philly_crimes_sf) + tm_polygons(&quot;homic_rate&quot;, style=&quot;quantile&quot;, title=&quot;Philadelphia \\nhomicide density \\nper sqKm&quot;) tmap has a very nice feature that allows us to give basic interactivity to the map. We can switch from “plot” mode into “view” mode and call the last plot, like so: tmap_mode(&quot;view&quot;) tmap_last() Cool huh? The tmap library also includes functions for simple spatial operations, geocoding and reverse geocoding using OSM. For more check vignette(\"tmap-getstarted\"). 3.4 Raster with tmap tmap can also plot raster files natively, for example: tmap_mode(&quot;plot&quot;) #&gt; tmap mode set to plotting tm_shape(HARV_DTM)+ tm_raster(style = &quot;cont&quot;, palette = &quot;viridis&quot;)+ tm_layout(legend.outside = TRUE) #&gt; stars object downsampled to 1114 by 897 cells. See tm_shape manual (argument raster.downsample) See Elegant and informative maps with tmap for more options. 3.5 Web mapping with leaflet leaflet provides bindings to the ‘Leaflet’ JavaScript library, “the leading open-source JavaScript library for mobile-friendly interactive maps”. We have already seen a simple use of leaflet in the tmap example. The good news is that the leaflet library gives us loads of options to customize the web look and feel of the map. The bad news is that the leaflet library gives us loads of options to customize the web look and feel of the map. Let’s build up the map step by step. First we load the leaflet library. Use the leaflet() function with an sp or Spatial* object and pipe it to addPolygons() function. It is not required, but improves readability if you use the pipe operator %&gt;% to chain the elements together when building up a map with leaflet. And while tmap was tolerant about our AEA projection of philly_crimes_sf, leaflet does require us to explicitly reproject the sf object. library(leaflet) # reproject philly_WGS84 &lt;- st_transform(philly_crimes_sf, 4326) leaflet(philly_WGS84) %&gt;% addPolygons() To map the homicide density we use addPolygons() and: remove stroke (polygon borders) set a fillColor for each polygon based on homic_rate and make it look nice by adjusting fillOpacity and smoothFactor (how much to simplify the polyline on each zoom level). The fill color is generated using leaflet’s colorQuantile() function, which takes the color scheme and the desired number of classes. To constuct the color scheme colorQuantile() returns a function that we supply to addPolygons() together with the name of the attribute variable to map. add a popup with the homic_rate values. We will create as a vector of strings, that we then supply to addPolygons(). pal_fun &lt;- colorQuantile(&quot;YlOrRd&quot;, NULL, n = 5) p_popup &lt;- paste0(&quot;&lt;strong&gt;Homicide Rate: &lt;/strong&gt;&quot;, philly_WGS84$homic_rate) leaflet(philly_WGS84) %&gt;% addPolygons( stroke = FALSE, # remove polygon borders fillColor = ~pal_fun(homic_rate), # set fill color with function from above and value fillOpacity = 0.8, smoothFactor = 0.5, # make it nicer popup = p_popup) # add popup Here we add a basemap, which defaults to OSM, with addTiles() leaflet(philly_WGS84) %&gt;% addPolygons( stroke = FALSE, fillColor = ~pal_fun(homic_rate), fillOpacity = 0.8, smoothFactor = 0.5, popup = p_popup) %&gt;% addTiles() Lastly, we add a legend. We will provide the addLegend() function with: the location of the legend on the map the function that creates the color palette the value we want the palette function to use a title leaflet(philly_WGS84) %&gt;% addPolygons( stroke = FALSE, fillColor = ~pal_fun(homic_rate), fillOpacity = 0.8, smoothFactor = 0.5, popup = p_popup) %&gt;% addTiles() %&gt;% addLegend(&quot;bottomright&quot;, # location pal=pal_fun, # palette function values=~homic_rate, # value to be passed to palette function title = &#39;Philadelphia homicide density per sqkm&#39;) # legend title The labels of the legend show percentages instead of the actual value breaks3. To set the labels for our breaks manually we replace the pal and values with the colors and labels arguments and set those directly using brewer.pal() and breaks_qt from an earlier section above. leaflet(philly_WGS84) %&gt;% addPolygons( stroke = FALSE, fillColor = ~pal_fun(homic_rate), fillOpacity = 0.8, smoothFactor = 0.5, popup = p_popup) %&gt;% addTiles() %&gt;% addLegend(&quot;bottomright&quot;, colors = brewer.pal(7, &quot;YlOrRd&quot;), labels = paste0(&quot;up to &quot;, format(breaks_qt$brks[-1], digits = 2)), title = &#39;Philadelphia homicide density per sqkm&#39;) That’s more like it. Finally, I have added for you a control to switch to another basemap and turn the philly polygon off and on. Take a look at the changes in the code below. leaflet(philly_WGS84) %&gt;% addPolygons( stroke = FALSE, fillColor = ~pal_fun(homic_rate), fillOpacity = 0.8, smoothFactor = 0.5, popup = p_popup, group = &quot;philly&quot;) %&gt;% addTiles(group = &quot;OSM&quot;) %&gt;% addProviderTiles(&quot;CartoDB.DarkMatter&quot;, group = &quot;Carto&quot;) %&gt;% addLegend(&quot;bottomright&quot;, colors = brewer.pal(7, &quot;YlOrRd&quot;), labels = paste0(&quot;up to &quot;, format(breaks_qt$brks[-1], digits = 2)), title = &#39;Philadelphia homicide density per sqkm&#39;) %&gt;% addLayersControl(baseGroups = c(&quot;OSM&quot;, &quot;Carto&quot;), overlayGroups = c(&quot;philly&quot;)) If you’d like to take this further here are a few pointers. Leaflet for R rayshader: Create Maps and Visualize Data in 2D and 3D Here is an example using ggplot, leaflet, shiny, and RStudio’s flexdashboard template to bring it all together. The formatting is set with labFormat() and in the documentation we discover that: “By default, labFormat is basically format(scientific = FALSE,big.mark = ',') for the numeric palette, as.character() for the factor palette, and a function to return labels of the form x[i] - x[i + 1] for bin and quantile palettes (in the case of quantile palettes, x is the probabilities instead of the values of breaks).”↩︎ "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
